{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click this For Kaggle Kernel link :\n",
    "<a href=\"https://www.kaggle.com/vinodsunny1/eda-xgboost-for-predicting-fare-amount/#data\" > Kaggle Kernel </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('../input/nyccar/nyc.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy  as np      # linear algebra\n",
    "import pandas as pd      # data processing\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#sns.set_style('darkgrid')\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/train.csv',nrows = 500000)\n",
    "test  = pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/test.csv')\n",
    "train = train.iloc[:,1:]\n",
    "test  = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Data Cleaning and Exploratory Data Analysis .**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data size \",train.shape)\n",
    "print(\"test  data size \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values (if any apply the appropriate method to handle them)\n",
    "l = [\"train set\", \"test set\"]\n",
    "j = 0\n",
    "for i in [train,test]:\n",
    "    print(l[j],\" : \\n\")\n",
    "    print(i.isnull().sum().sort_values(ascending = False))\n",
    "    print(\"\\n \\n\")\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the rows with missing values \n",
    "train.dropna(axis = 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we are good to go\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us see  an overview of our dataset \n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insight <br>\n",
    "1 . notice we have negative values for fare_amount and it makes no sense at all,because fare can't be negative . <br>\n",
    "2 . passenger count  = 0 ,it means no ride at all which inturn no fare value should be available for that instances (row ) or if         fare exists it simply the fare for waiting charge given to the cab driver after cab cancellation by the customer . <br>\n",
    "3 . we know ( source internet ) \n",
    "    * Latitudes range from -90 to 90, and longitudes range from -180 to 80.\n",
    "\n",
    "    * Latitude and longitude  of New York city is  40.730610 ,-73.935242  respectively ,\n",
    "     But the values for longitude and latitude in pickup and dropoff columns are much different from the actual NYC lat and lan ,\n",
    "     those different  lat and lan values are acting has as outlier in our dataset .\n",
    "<a href=\"https://www.latlong.net/place/new-york-city-hall-ny-usa-5431.html\">Check Here</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with negtaive fare values .\n",
    "print(\"Min value Before Dropping Negative values from  fare column : \",train.fare_amount.min())\n",
    "train = train[train.fare_amount > 0].iloc[:,:]\n",
    "print(\"Min value After Dropping Negative values from  fare column  : \",train.fare_amount.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as you can see lat and lan values are too varying w.r.t to ,\n",
    "# actual Lat and long values ranging  from -90 to 90 to -180 to 80 respectively .\n",
    "print(\" pickup_longitude : \",min(train.pickup_longitude),max(train.pickup_longitude))\n",
    "print(\" pickup_latitude  : \",min(train.pickup_latitude),max(train.pickup_latitude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train.pickup_longitude >  -180) & (train.pickup_longitude < 80)]\n",
    "train = train[(train.pickup_latitude >  -90)   & (train.pickup_latitude < 90)]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as you can see lat and lan values are too varying w.r.t to ,\n",
    "# actual Lat and long values ranging  from -90 to 90 to -180 to 80 respectively .\n",
    "print(\" dropoff_longitude : \",min(train.dropoff_longitude),max(train.dropoff_longitude))\n",
    "print(\" dropoff_latitude  : \",min(train.dropoff_latitude),max(train.dropoff_latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train.dropoff_longitude >  -180) & (train.dropoff_longitude < 80)]\n",
    "train = train[(train.dropoff_latitude >  -90)   & (train.dropoff_latitude < 90)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for test set\n",
    "train = train[(train.pickup_longitude  >  -180)  & (train.pickup_longitude < 80)]\n",
    "train = train[(train.pickup_latitude   >  -90)   & (train.pickup_latitude  < 90)] \n",
    "train = train[(train.dropoff_longitude >  -180)  & (train.dropoff_longitude< 80)]\n",
    "train = train[(train.dropoff_latitude  >  -90)   & (train.dropoff_latitude < 90)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Calculate distance variable by using haversine formula with the help of pickup and dropup lat and long values  .\n",
    "<a href=\"https://en.wikipedia.org/wiki/Haversine_formula\">Check Here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dist(slat,slong,elat,elong):\n",
    "    data = [train,test]\n",
    "    for i in data:\n",
    "        phi1 = np.radians(i[slat])\n",
    "        phi2 = np.radians(i[elat])\n",
    "        delta_phi = np.radians(i[elat]-i[slat])\n",
    "        delta_lambda = np.radians(i[elong]-i[slong])\n",
    "        #a = sin²((φB - φA)/2) + cos φA . cos φB . sin²((λB - λA)/2)\n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2 \n",
    "        #c = 2 * atan2( √a, √(1−a) )\n",
    "        c = 2 * np.arctan2(np.sqrt(a),np.sqrt(1-a))\n",
    "    \n",
    "        d = 6371 * c\n",
    "        i[\"distance\"] = d\n",
    "\n",
    "find_dist(\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Create new Variable using DateTime Future ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime']  = pd.to_datetime(train['pickup_datetime'],format='%Y-%m-%d %H:%M:%S UTC')\n",
    "test['pickup_datetime']   = pd.to_datetime(test['pickup_datetime'],format='%Y-%m-%d %H:%M:%S UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df in [train,test]:\n",
    "    df['year']  = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['date']  = df['pickup_datetime'].dt.day\n",
    "    df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "    df['hour']  = df['pickup_datetime'].dt.hour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\"> univariate analysis  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"fare_amount\",\"passenger_count\",\"distance\"]\n",
    "plt.figure(figsize = (18,4),facecolor = \"white\")\n",
    "plot_num = 1\n",
    "\n",
    "for i in cols:\n",
    "    if(plot_num<=3):\n",
    "        ax = plt.subplot(1,3,plot_num)\n",
    "        sns.distplot(train[i],color = 'red')\n",
    "        plt.xlabel(i,fontsize = 15)\n",
    "    plot_num+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insights  : <br>\n",
    "<br>\n",
    "### 1 . fare_amount distribution is highly skewed towards right  which simply means the following assumptions .<br>\n",
    "    a . only few cab customers travelled for longer distance .  \n",
    "    b . high fare amount might be the total price for the cab ride including tips given  to the cab driver .\n",
    "\n",
    "### 2 . from passenger_count distribution ,it clearly shows that most of the cab customer are single passenger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year v/s average fare price\n",
    "# insight : fare price increasing year by year . \n",
    "pd.pivot_table(train,values = \"fare_amount\",index = \"year\",aggfunc = \"mean\").plot(kind = 'bar',color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see extreme fare_amounts that are acting as outliers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['fare_amount'],color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate interquantile range for fare_amount feature \n",
    "q1  = train['fare_amount'].quantile(0.25)\n",
    "q3  = train['fare_amount'].quantile(0.75)\n",
    "iqr =  q3 - q1\n",
    "lb  =  q1 - 1.5*iqr\n",
    "ub  =  q3 + 1.5*iqr\n",
    "print(\"Fare Amount : \")\n",
    "print(\"lower bound : \",lb,\"upper bound : \",ub)\n",
    "# but i am still i am not going to remove any outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[(train[\"fare_amount\"]>0) & (train[\"fare_amount\"] <=22.5) ].iloc[:,:]\n",
    "\n",
    "plt.figure(figsize = (16,4),facecolor = \"white\")\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.distplot(train[\"fare_amount\"],ax = ax,color = 'red')\n",
    "plt.xlabel(\"fare amount distribution \",fontsize = 15)\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.boxplot(train[\"fare_amount\"],ax = ax,color = 'red')\n",
    "plt.xlabel(\"fare amount boxplot \",fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insight : it seems most of the cab rides took with in 10kms by the cab passengers . \n",
    "bin_0 =  train.loc[(train['distance'] == 0), ['distance']]\n",
    "bin_1 =  train.loc[(train['distance']>0)&(train['distance']<=10),['distance']]\n",
    "bin_2 =  train.loc[(train['distance']>10)&(train['distance']<=50),['distance']]\n",
    "bin_3 =  train.loc[(train['distance']>50)&(train['distance']<=100),['distance']]\n",
    "bin_4 = train.loc[(train['distance']>100)&(train['distance']<=250),['distance']]\n",
    "bin_5 = train.loc[(train['distance']>250),['distance']]\n",
    "bin_0['bins'] = '0'\n",
    "bin_1['bins'] = '1-10'\n",
    "bin_2['bins'] = '11-50'\n",
    "bin_3['bins'] = '51-100'\n",
    "bin_4['bins'] = '101-250'\n",
    "bin_5['bins'] = '>250'\n",
    "dist_bins = pd.concat([bin_0,bin_1,bin_2,bin_3,bin_4,bin_5],axis = 0)\n",
    "sns.countplot(dist_bins['bins'])\n",
    "plt.xlabel(\"Distance bins\",fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems no relationship between day_of_week with passengers count\n",
    "sns.boxplot(y = train[\"passenger_count\"],x = train[\"day_of_week\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"green\"> Bivariate Analysis </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insight :  most of the cab customers are single passengers .\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.scatterplot(x = train[\"passenger_count\"],y =train['fare_amount'],color = 'red')\n",
    "plt.xlabel(\"passenger_count \",fontsize = 15)\n",
    "plt.ylabel(\"fare_amount \",fontsize = 15)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insight : fare_amount is high during 5am to 5pm ,that might be due to people used to travel during day time only.\n",
    "# eg : people working in IT sector .  \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['hour'], y=train['fare_amount'], s=2,color = 'red')\n",
    "plt.xlabel(\"hour\",fontsize = 15)\n",
    "plt.ylabel(\"fare_amount \",fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insight : The highest fares seem to be on a Sunday and Monday,Saturday , it may be due to people travel far distances on Saturday, Sunday  (visiting family and returning back home) and Monday, and hence, the high fares. and fare amount seems low during Tuesday ,wednesday,Thurshday,Friday .\n",
    "### eg : people working in IT sector . \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=train['day_of_week'], y=train['fare_amount'], s=2,color = 'red')\n",
    "plt.xlabel(\"day_of_week\",fontsize = 15)\n",
    "plt.ylabel(\"fare_amount \",fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['fare_amount','distance']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's dig more information about relationship between fare and distance . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 : when, fare = some valid value and distance = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many number of cancellation has been occured by the cab customer ?\n",
    "cancelled_trip = train[train.distance==0].loc[:,[\"fare_amount\",\"distance\",\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\"]]\n",
    "print(\"cancelled_trip count :\",len(cancelled_trip))\n",
    "cancelled_trip.head(5)\n",
    "# the reason why i am calling this as a cancelled_trip is because of same latitute and longitude values for for both pickup and dropup column . \n",
    "# and we can see below, some fare has been charged even though the distance is equal to = 0 ,this may be due to waiting charge collected from customer if they have cancelled the cab ride ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2 : longer distance v/s low fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare_amount is to very low even though distance is high ,\n",
    "# it may due to wrong lat and long values assigned to this instances (error) which are used to calculate distance between start and end point of ride !.\n",
    "train[['fare_amount','distance']].sort_values(by = \"distance\",axis = 0,ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes did you see that !!!!\n",
    "plt.figure(figsize = (16,4),facecolor = \"white\")\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.boxplot(train[\"distance\"],ax = ax,color = 'red')\n",
    "plt.xlabel(\"Distance (boxplot)\",)\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.distplot(train.distance,ax = ax,color = 'red')\n",
    "plt.xlabel(\"Distance (distribution)\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let me remove those extreme distance which are acting as outlier with the help pf IQR method .\n",
    "q1,q3 = train.distance.quantile(0.25),train.distance.quantile(0.75)\n",
    "IQR   = q3 - q1 \n",
    "low_bound   = q1 - IQR*1.5\n",
    "upper_bound = q3 + IQR*1.5\n",
    "print(\"low_bound : \",low_bound,\"upper_bound : \",upper_bound)\n",
    "# distance in negetive is meaningless , \n",
    "# i am going to consider instances with distances <= 50 kms (my assumption )\n",
    "# generally city taxi's are not for longer distance travel . That's a city limited !!!!(my assumption )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"instances with distances greater than 50kms : \",len(train[train.distance>50]))\n",
    "print(\"instances with distances lesser than  50kms : \",len(train[train.distance<50]))\n",
    "train = train[train.distance<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i am not going to drop pickup_datetime col from my both train and test sets .\n",
    "train.drop(['pickup_datetime'],axis = 1,inplace = True)\n",
    "test.drop(['pickup_datetime'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation map\n",
    "plt.figure(figsize = (16,4),facecolor = \"white\")\n",
    "sns.heatmap(train.corr(),annot= True,cmap = 'rainbow_r',annot_kws = {\"Size\":14})\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "# insight : distance feature is highly correlated with fare_amount . \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Predicting values for test cases !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split data as per model requirment \n",
    "xtrain = train.drop([\"fare_amount\"],axis = 1)\n",
    "ytrain = train[\"fare_amount\"]\n",
    "print(\"xtrain shape : \",xtrain.shape)\n",
    "print(\"ytrain shape : \",ytrain.shape)\n",
    "# ------------------------------------------ # \n",
    "xtest = test.iloc[:,:]\n",
    "print(\"xtest  shape  : \",xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i am using xgboost for the very first time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from xgboost import plot_importance\n",
    "model = XGBRegressor(n_estimators=100,\n",
    "                    learning_rate = .1,\n",
    "                    max_depth = 6,\n",
    "                    random_state=42,\n",
    "                    n_jobs = -1,\n",
    "                    early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    xtrain, \n",
    "    ytrain, \n",
    "    eval_metric=\"rmse\",\n",
    "    verbose=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(xtrain)\n",
    "print(\"MSE  for train set : \",mean_squared_error(ytrain,y_train_pred))\n",
    "print(\"RMSE for train set : \",mean_squared_error(ytrain,y_train_pred)**0.5)\n",
    "print(\"r2_score for train set: \",r2_score(ytrain,y_train_pred))\n",
    "r2_val = r2_score(ytrain,y_train_pred)\n",
    "n = len(xtrain)\n",
    "p = xtrain.shape[1]\n",
    "adjusted_r2_val  = 1 - ( ((1-r2_val)*(n-1)) / (n-p-1) )\n",
    "print(\"adjusted r2_score for train set: \",adjusted_r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ytrain - y_train_pred ).set_title(\"error distribution between actual and predicted values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot feature Importance graph\n",
    "figsize=(10,10)\n",
    "fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "plot_importance(model,ax = ax,height = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let me consider first 7 features only and train our model once again so that is there any  chance we can\n",
    "# observe in increase of accuracy of model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train = train[[\"pickup_latitude\",\"distance\",\"pickup_longitude\",\"dropoff_longitude\",\"dropoff_latitude\",\"hour\",\"year\"]]\n",
    "y2_train = train[\"fare_amount\"]\n",
    "x2_test  = test[[\"pickup_latitude\",\"distance\",\"pickup_longitude\",\"dropoff_longitude\",\"dropoff_latitude\",\"hour\",\"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model1 = XGBRegressor(n_estimators=100,\n",
    "                    learning_rate = .1,\n",
    "                    max_depth = 6,\n",
    "                    random_state=42,\n",
    "                    n_jobs = -1,\n",
    "                    early_stopping_rounds=10)\n",
    "model1.fit(\n",
    "    x2_train, \n",
    "    y2_train, \n",
    "    eval_metric=\"rmse\",\n",
    "    verbose=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train_pred = model1.predict(x2_train)\n",
    "print(\"MSE  for train set : \",mean_squared_error(y2_train,y2_train_pred))\n",
    "print(\"RMSE for train set : \",mean_squared_error(y2_train,y2_train_pred)**0.5)\n",
    "print(\"r2_score for train set: \",r2_score(y2_train,y2_train_pred))\n",
    "r2_val = r2_score(y2_train,y2_train_pred)\n",
    "n = len(x2_train)\n",
    "p = x2_train.shape[1]\n",
    "adjusted_r2_val  = 1 - ( ((1-r2_val)*(n-1)) / (n-p-1) )\n",
    "print(\"adjusted r2_score for train set: \",adjusted_r2_val)\n",
    "print(\"Accuracy not improved by !!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y2_train - y2_train_pred ).set_title(\"error distribution between actual and predicted values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You :) keep learning .\n",
    "please do provide any constructive suugestions for the above work i'll glad to here  ,please do up vote this kernel if you found it useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "Image('../input/thankyou/j.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
